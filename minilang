#!/usr/bin/env python3

class MiniLangLexer:
    def __init__(self, source_code, tab=4):
        self.source = source_code
        self.posicion = 0
        self.linea = 1
        self.colum = 1
        self.tab = tab

        self.tokens = []
        self.errores = []

        self.inicio_de_linea = True
        self.linea_tiene_token = False

        self.pila_indent = [0]

        self.keywords = {
            "int": "KW_INT",
            "float": "KW_FLOAT",
            "string": "KW_STRING",
            "bool": "KW_BOOL",
            "if": "KW_IF",
            "else": "KW_ELSE",
            "while": "KW_WHILE",
            "func": "KW_FUNC",
            "Read": "KW_READ",
            "Write": "KW_WRITE",
            "true": "BOOL",
            "false": "BOOL",
        }

    def caracter_actual(self):
        if self.posicion >= len(self.source):
            return None
        return self.source[self.posicion]

    def mirar_siguiente(self):
        if self.posicion + 1 >= len(self.source):
            return None
        return self.source[self.posicion + 1]

    def avanzar(self):
        ch = self.caracter_actual()
        self.posicion += 1

        if ch == '\n':
            self.linea += 1
            self.colum = 1
            self.inicio_de_linea = True
        else:
            self.colum += 1
        return ch


    def agregar_token(self, tipo, lexema, lin, cini, cfin):
        self.tokens.append({
            "tipo": tipo,
            "lexema": lexema,
            "linea": lin,
            "col_ini": cini,
            "col_fin": cfin
        })

    def error(self, msg):
        self.errores.append(msg)

    # Comentarios / NEWLINE
    def ignorar_comen(self):
        while self.caracter_actual() not in ('\n', None):
            self.avanzar()

    def newline(self):
        # NEWLINE solo si esa línea tuvo tokens "reales"
        if self.linea_tiene_token:
            # La línea que terminó es (self.linea - 1)
            self.agregar_token("NEWLINE", "\\n", self.linea - 1, 1, 1)

        self.linea_tiene_token = False
        self.inicio_de_linea = True

    def consumir_indent(self):
        col = 0
        while True:
            ch = self.caracter_actual()
            if ch == ' ':
                self.avanzar()
                col += 1
            elif ch == '\t':
                self.avanzar()
                col += self.tab - (col % self.tab)
            else:
                break

        # Si la línea es vacía o comentario, no emitimos indent/dedent
        if self.caracter_actual() in ('\n', None, '#'):
            return

        cima = self.pila_indent[-1]
        if col > cima:
            self.pila_indent.append(col)
            self.agregar_token("INDENT", "", self.linea, 1, 1)
        elif col < cima:
            while len(self.pila_indent) > 1 and self.pila_indent[-1] > col:
                self.pila_indent.pop()
                self.agregar_token("DEDENT", "", self.linea, 1, 1)

            if self.pila_indent[-1] != col:
                self.error(f"[IndentError] Línea {self.linea}: indentación inválida {col} (no coincide con pila).")

        self.inicio_de_linea = False

    def es_letra(self, ch):
        return ('a' <= ch <= 'z') or ('A' <= ch <= 'Z') or ch == '_'

    def es_digito(self, ch):
        return '0' <= ch <= '9'

    def leer_identificador(self):
        lin = self.linea
        cini = self.colum
        lex = ""

        while True:
            ch = self.caracter_actual()
            if ch is None:
                break
            if self.es_letra(ch) or self.es_digito(ch):
                lex += self.avanzar()
            else:
                break

        if len(lex) > 31:
            self.error(f"[LexError] Línea {lin}, col {cini}: ID >31 caracteres '{lex}'.")
            lex = lex[:31]  # recorte para seguir

        tipo = self.keywords.get(lex, "ID")
        self.agregar_token(tipo, lex, lin, cini, cini + len(lex) - 1)
        self.linea_tiene_token = True

    def leer_numero(self):
        lin = self.linea
        cini = self.colum
        lex = ""

        while True:
            ch = self.caracter_actual()
            if ch is None or not self.es_digito(ch):
                break
            lex += self.avanzar()

        # float simple: dígitos '.' dígitos
        if self.caracter_actual() == '.' and self.es_digito(self.mirar_siguiente() or ''):
            lex += self.avanzar()  # '.'
            while self.es_digito(self.caracter_actual() or ''):
                lex += self.avanzar()
            self.agregar_token("FLOTANTE", lex, lin, cini, cini + len(lex) - 1)
            self.linea_tiene_token = True
            return

        # entero sin ceros a la izquierda (excepto "0")
        if len(lex) > 1 and lex[0] == '0':
            self.error(f"[LexError] Línea {lin}, col {cini}: entero con cero a la izquierda '{lex}'.")

        self.agregar_token("ENTERO", lex, lin, cini, cini + len(lex) - 1)
        self.linea_tiene_token = True

    def leer_cadena_simple(self):
        lin = self.linea
        cini = self.colum
        lex = self.avanzar()  # consume la comilla inicial "

        while True:
            ch = self.caracter_actual()
            if ch is None or ch == '\n':
                self.error(f"[LexError] Línea {lin}, col {cini}: cadena sin cerrar.")
                self.agregar_token("CADENA_ERROR", lex, lin, cini, self.colum)
                self.linea_tiene_token = True
                return

            if ch == '"':
                lex += self.avanzar()
                self.agregar_token("CADENA", lex, lin, cini, cini + len(lex) - 1)
                self.linea_tiene_token = True
                return

            lex += self.avanzar()


    def tokenize(self):
        while self.caracter_actual() is not None:
            ch = self.caracter_actual()

            # Manejar indent al inicio de línea
            if self.inicio_de_linea:
                if ch in (' ', '\t'):
                    self.consumir_indent()
                    continue
                elif ch == '\n':
                    self.avanzar()
                    self.newline()
                    continue
                elif ch == '#':
                    self.ignorar_comen()
                    continue
                else:
                    self.inicio_de_linea = False

            # comentario
            if ch == '#':
                self.ignorar_comen()
                continue

            # salto de línea
            if ch == '\n':
                self.avanzar()
                self.newline()
                continue

            # espacios
            if ch in (' ', '\t', '\r'):
                self.avanzar()
                continue

            # cadena
            if ch == '"':
                self.leer_cadena_simple()
                continue

            # ID / keyword
            if self.es_letra(ch):
                self.leer_identificador()
                continue

            # número
            if self.es_digito(ch):
                self.leer_numero()
                continue

            # operadores de 2 caracteres primero
            dos = (ch or '') + (self.mirar_siguiente() or '')
            if dos in ("!=", "==", "<=", ">="):
                lin, cini = self.linea, self.colum
                self.avanzar(); self.avanzar()
                tipo = {"!=": "NE", "==": "EQEQ", "<=": "LE", ">=": "GE"}[dos]
                self.agregar_token(tipo, dos, lin, cini, cini + 1)
                self.linea_tiene_token = True
                continue

            # operadores 1 caracter
            if ch in "+-*/%":
                lin, cini = self.linea, self.colum
                self.avanzar()
                tipo = {"+": "PLUS", "-": "MINUS", "*": "STAR", "/": "SLASH", "%": "MOD"}[ch]
                self.agregar_token(tipo, ch, lin, cini, cini)
                self.linea_tiene_token = True
                continue

            if ch in "<>=":
                lin, cini = self.linea, self.colum
                self.avanzar()
                tipo = {"<": "LT", ">": "GT", "=": "EQ"}[ch]
                self.agregar_token(tipo, ch, lin, cini, cini)
                self.linea_tiene_token = True
                continue

            # símbolos especiales
            if ch in "{}()[];:,":
                lin, cini = self.linea, self.colum
                self.avanzar()
                tipo = {
                    "{": "LBRACE", "}": "RBRACE",
                    "(": "LPAREN", ")": "RPAREN",
                    "[": "LBRACK", "]": "RBRACK",
                    ";": "SEMI", ":": "COLON", ",": "COMMA",
                }[ch]
                self.agregar_token(tipo, ch, lin, cini, cini)
                self.linea_tiene_token = True
                continue

            # carácter inválido
            self.error(f"[LexError] Línea {self.linea}, col {self.colum}: carácter inválido '{ch}'.")
            self.avanzar()

        # si el archivo terminó sin newline final, no obligamos NEWLINE
        # cerrar dedents pendientes
        while len(self.pila_indent) > 1:
            self.pila_indent.pop()
            self.agregar_token("DEDENT", "", self.linea, 1, 1)

        self.agregar_token("EOF", "", self.linea, 1, 1)
        return self.tokens, self.errores



def ruta_out_misma(ruta_entrada):
    # reemplaza .mlng por .out; si no termina en .mlng, añade .out
    nombre_base = ruta_entrada.split("/")[-1]   # prueba1.mlng
    nombre_sin_ext = nombre_base.replace(".mlng", "")
    return "salidas/" + nombre_sin_ext + ".out"

def escribir_out(ruta_out, tokens):
    with open(ruta_out, "w", encoding="utf-8") as f:
        for t in tokens:
            tipo = t["tipo"]
            lex = t["lexema"]
            lin = t["linea"]
            cini = t["col_ini"]
            cfin = t["col_fin"]
            if lex != "":
                f.write(f"({lin}, {cini}-{cfin}) {tipo}  valor={lex}\n")
            else:
                f.write(f"({lin}, {cini}-{cfin}) {tipo}\n")


def main():
    print("MiniLang Lexer (Fase 1)")
    archivo = input("Archivo de entrada (.mlng): ").strip()

    if archivo == "":
        print("Error: no se ingresó archivo.")
        return

    ruta = "pruebas/" + archivo

    # Abrir archivo (si falla, NO generamos .out)
    try:
        with open(ruta, "r", encoding="utf-8") as f:
            code = f.read()
    except Exception as e:
        print(f"Error: no se pudo abrir el archivo. ({e})")
        return

    lexer = MiniLangLexer(code, tab=4)
    tokens, errores = lexer.tokenize()

    ruta_out = ruta_out_misma(ruta)
    escribir_out(ruta_out, tokens)

    # Salida secundaria
    if len(errores) == 0:
        print("Éxito: no se encontraron errores léxicos.")
    else:
        print("Errores léxicos encontrados:")
        for e in errores:
            print(e)

    print("Salida principal escrita en:", ruta_out)


if __name__ == "__main__":
    main()